{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Настройка нейросетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Функции потерь\n",
    "* Мы использовали функцию потерь $L(y, \\tilde y) = (y - \\tilde y)^2$ при обучении перцептронов.\n",
    "* При разборе устройства классификатора использовали\n",
    "\\begin{equation*}\n",
    "    L(k,l)  = \\left\\lbrace \n",
    "        \\begin{array}{rl}\n",
    "            0, & \\mbox{если } l= k \\mbox{ (корректный ответ)}\\\\\n",
    "            1, & \\mbox{если } l\\neq k \\mbox{ и } l\\in \\{1,2,\\dots,K\\} \\\\\n",
    "            d, & \\mbox{если } l=\\mathscr{D} \\mbox{ (в затруднении)}.\n",
    "        \\end{array}  \\right. \n",
    "\\end{equation*}\n",
    "* В коде примеров на TensorFlow использовали перекрестную энтропию $L(p,q)=-\\Sigma_x{p(x) \\log q(x)}$.\n",
    "* ...\n",
    "\n",
    "Все эти функции показывают, насколько плоха наша модель, и мы обучали модель, минимизируя фунции потерь.\n",
    "\n",
    "**Выбор функции потерь - важный аспект проектирования нейросети.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Метод максимального правдоподобия для НС\n",
    "\n",
    "Нейросеть можно рассматривать как вероятностную модель. Она принимает на вход параметры объекта $x$, возвращает ответ $y$, который можно рассматривать как случайную величину.\n",
    "\n",
    "Т.е. нейросетевая модель строит распределение вероятностей\n",
    "$$\n",
    "p(y | x; \\theta),\n",
    "$$\n",
    "$\\theta$ -- независимые параметры модели.\n",
    "\n",
    "Как и с обычной вероятностной моделью мы можем воспользоваться методом максимального правдоподобия для оценки параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Метод максимального правдоподобия\n",
    "\n",
    "Есть входные примеры $x_1, x_2, \\dots, x_n$ и ответы $y_1, y_2, \\dots, y_n$. Рассчитаем вероятность получения ответов $y_1, y_2, \\dots, y_n$ при известных $x_1, x_2, \\dots, x_n$:\n",
    "\n",
    "$$\n",
    "P(\\theta) = p(y_1 | x_1; \\theta) p(y_2 | x_2; \\theta) \\dots p(y_n | x_n; \\theta)\n",
    "$$\n",
    "нужно подобрать параметры $\\theta$, чтобы получить максимальную вероятность $P(\\theta)$.\n",
    "\n",
    "Обычно имеют дело с отрицательным (у нас задача минимизации) логарифмом вероятностей $J(\\theta) = -\\log P(\\theta)$:\n",
    "\n",
    "$$\n",
    "J(\\theta) = - \\sum_{i=1}^n \\log p(y_i | x_i; \\theta)\n",
    "$$\n",
    "\n",
    "*Например, для регрессии $p_{model}(y | x) = N(y, f(x, \\theta), I)$ данный метод приводит к функции потерь $L=(y -f(x, \\theta))^2$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Зачем такой подход нужен?\n",
    "\n",
    "* Единообразие: нет необходимости проектировать функцию потерь заново под каждую задачу.\n",
    "* Есть функции активации с насыщением, в которых фигурирует $e^u$ => изчезающий градиент. Если использовать логарифмическую функцию потерь, логарифм компенсирует экспоненту, градиент везде \"хороший\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Функции активации\n",
    "\n",
    "* Выходные блоки.\n",
    "* Скрытые блоки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Выходные блоки\n",
    "\n",
    "Выбор функции активации выходного блока и функции потерь тесно связаны.\n",
    "\n",
    "Пусть $h$ -- выходы скрытого слоя, $W$ -- весовые коэффициенты, $b$ -- пороги.\n",
    "\n",
    "#### Задача регрессии \n",
    "\n",
    "Линейная функция активации, порождающая условное среднее:\n",
    "$$\n",
    "p(y|x) = N(y, W h + b, I).\n",
    "$$\n",
    "Минимизация максимального правдоподобия эквивалентна минимизации среднеквадратической ошибки\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{i-1}^n(y_i - \\hat y_i)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Прогноз бинарной величины. \n",
    "\n",
    "Рассматриваем выход сети как вероятность $\\hat y = P(y=1| x)$ => функция активации сигмоидальная: $sigm(Wh + b)$\n",
    "\n",
    "\n",
    "**Не надо** использовать функцию потерь \n",
    "$$(y- sigm(Wh + b))^2.$$\n",
    "\n",
    "Метод логарифмического правдоподобия приведет к формуле:\n",
    "$$\n",
    "J(\\theta) = \\log[1 + e^{(1-2y)(Wh + b)} ].\n",
    "$$\n",
    "В этом случае насыщение достигается, если ответ уже получен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Номинальные величины\n",
    "\n",
    "* Ранее была бинарная величина:  $\\hat y = P(y=1| x)$? и сигмоидная функция активации.\n",
    "* Сейчас несколько: $\\hat y_i = P(y=i| x)$. При этом нужно:\n",
    " 1. каждый $\\hat y_i \\in [0, 1]$\n",
    " 2. $\\sum \\hat y_i = 1$\n",
    "\n",
    "Воспользуемся функцией $softmax$:\n",
    "\n",
    "$$\n",
    "softmax(z_i) = \\frac{e^{z_i}}{\\sum_i e^{z_i}} \n",
    "$$\n",
    "\n",
    "Метод логарифмического правдоподобия будет удобен, т.к. логарифм \"уничтожит\" экспоненту:\n",
    "$$\n",
    "log(softmax(z_i)) = z_i - log(\\sum e^{z_i}).\n",
    "$$\n",
    "\n",
    "Насыщения нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Общие рекомендации по функциям активации\n",
    "\n",
    "1. Сигмоида:\n",
    " (+) ограничена;\n",
    " (-) насыщение;\n",
    " (-) не центрирована в 0;\n",
    " (-) $exp$ дорогая.\n",
    "\n",
    "2. Гиперболический тангенс:\n",
    " (+) ограничена;\n",
    " (-) насыщение;\n",
    " (+) центрирована;\n",
    " (-) $exp$ дорогая.\n",
    " \n",
    "3. ReLU:\n",
    " (+) нет насыщения;\n",
    " (+) вычислительно проста;\n",
    " (+) быстро сходится;\n",
    " (-) не центрирована в 0;\n",
    " (-) нет производной в 0;\n",
    " (-) \"мертвые\" нейроны.\n",
    " \n",
    "4. LeakyReLU:\n",
    " $\\max(0.001 x, x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Регуляризация\n",
    "\n",
    "Регуляризация -- стратегия уменьшения ошибки на этапе обобщения за счет увеличения ошибки на этапе обучения.\n",
    "\n",
    "* Обучение усложняется, когда размерность данных велика.\n",
    "\n",
    "* Чтобы алгоритм обучения хорошо обобщался (прогноз на тестовых данных), нужно иметь априорные знания о тех функциях, которые он должен изучить.\n",
    "\n",
    "* Частое предположение: гладкость функций, локальное постоянство. (Функция не должна сильно изменяться в на небольшом участке).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Штрафы по нормам параметров\n",
    "\n",
    "Регуляризированная функция потерь складывается из целевой функции и штрафа на величины (обычно нормы) параметров:\n",
    "$$\n",
    "\\tilde J(\\theta, X, y) = J(\\theta, X, y) + \\alpha \\Omega(\\theta),\n",
    "$$\n",
    "где $\\alpha \\in [0, 1)$ -- параметр \"силы\" регуляризации.\n",
    "\n",
    "#### Какие параметры регулиризуем?\n",
    "\n",
    " * Обычно штрафуют только веса $W$.\n",
    " * Пороги оставляют \"как есть\":\n",
    "   * для подбора порогов обычно нужно меньше примеров, чем для весов (вес -- взаимодействие двух переменных, порог - одной);\n",
    "   * ограничение порогов может быть причиной сильного недообучения.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Регуляризация по норме $L^2$\n",
    "\n",
    "$$\n",
    "\\tilde J(\\theta, X, y) = J(\\theta, X, y) + \\alpha w^T w\n",
    "$$\n",
    "\n",
    "![Регуляризация](img/tuning/regularization.png)\n",
    "\n",
    "### Регуляризация по норме $L^1$\n",
    "\n",
    "$$\n",
    "\\tilde J(\\theta, X, y) = J(\\theta, X, y) + \\alpha ||w||\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ансамбли моделей\n",
    "\n",
    "* Уменьшаем ошибку обобщения за счет комбинации нескольких моделей: \n",
    "  * обучаем раздельно несколько моделей, \n",
    "  * устраиваем голосование между ними.\n",
    "  \n",
    "(Разные модели ошибаются по-разному)\n",
    "\n",
    "Например, $k$ моделей регрессии, каждая модель делает ошибку $\\epsilon_i$ на $i$-м примере. Пусть для простоты ошибки нормально распределены с нулевым средним, дисперсиями $E(\\epsilon_i) = v$ и ковариациями $E(\\epsilon_i, \\epsilon_j) = c$.\n",
    "\n",
    " * Ошибка предсказания ансамбля: $\\frac 1k \\sum_i \\epsilon_i$.\n",
    " * Матожидание квадрата ошибки: $\\frac 1k v + \\frac{k-1}{k}c$.\n",
    "\n",
    "Два крайних случая:\n",
    "1. При идеальной корреляции ($c=v$), среднеквадратическая ошибка равна $v$ (усреднение не помогает). \n",
    "2. При некоррелированных ошибках ($c=0$) среднеквадратическая ошибка равна $\\frac 1k v$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Прореживание (Dropout)\n",
    "\n",
    "Эмпирический метод создания ансамблей моделей на базе нейросетей.\n",
    "![Прореживание](img/tuning/dropout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Каждый параметр сети при обучении может быть включен или выключен. \n",
    "2. При загрузке примера для обучения мы формируем случайную битовую маску, маркирующую, будет ли использоваться соотвествующий параметр в сети при обработке примера. Вероятность $p_{param=1}$ -- гиперпараметр алгоритма, обычно 0.5.\n",
    "3. Подаем пример, производим прямой и обратный проходы обучения (с учетом выключенных связей). \n",
    "\n",
    "Обученную таким образом сеть можно рассматривать, как ансамбль из огромного числа подсетей, частично разделяющих между собой параметры. Такая сеть более устойчива к шумам, менее подвержена переобучению и т.п.\n",
    "\n",
    "После обучения сети ее нужно \"собрать обратно\", включив все связи. Работает эмпирическое правило: если при обучении вероятность включения параметров была равна $p$, то вход в нейрон \"собранной\" сети будет выше в 1/p раз, чем при обучении. Поэтому в итоговой сети веса делят на $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сеть не обучается?\n",
    "\n",
    "1. Начинайте с самой простой модели, про которую известно, что она работает с вашими данными. Используйте стандартные функции потерь.    \n",
    "2. Сначала отключите все дополнительные \"фишки\" (регуляризацию, сгенерированные (аугментированные) данные, прореживание и т.п.).\n",
    "3. Убедитесь, что входные данные корректны.\n",
    "4. Обучитесь на маленьком наборе данных (2-20 примеров). Убедитесь, что сеть может воспроизвести их.\n",
    "5. Шаг за шагом добавляйте обратно все отключенные части (регуляризацию, свою функцию потерь и т.д.).\n",
    "\n",
    "[Сборник советов по диагностике работы нейросетей](https://blog.slavv.com/37-reasons-why-your-neural-network-is-not-working-4020854bd607)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Порядок важности настроек\n",
    "\n",
    "1. Архитектура сети (включая функции активации, функцию потерь, метод обучения).\n",
    "2. Параметры, отвечающие за скорость обучения.\n",
    "3. Регуляризация."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
