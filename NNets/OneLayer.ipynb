{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Однослойный перцептрон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Рассматриваем однослойную нейронную сеть.\n",
    "\n",
    "<img src=\"img/oneLayer/net.png\" height=\"30%\">\n",
    "Сеть состоит из $n$ нейронов, каждый нейрон имеет $m+1$ вход.\n",
    "У нейрона номер $i$ весовые коэффициенты $w_{0i}, w_{1i}, \\dots w_{mi}$ ($w_{0i}$ -- вес порогового входа, на схеме не показан).\n",
    "\n",
    "Видим, что нейрон номер $i$ никак не зависит от нейрона номер $j$ (нейроны могут обучаться независимо друг от друга)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Правило обучения Розенблатта\n",
    "\n",
    "Рассматриваем перцепртрон: однослойную нейронную сеть с порговой функцией активации. Без потери общности обучаем отдельный нейрон $i$.\n",
    "\n",
    "\\begin{equation}\n",
    "u = b+\\sum_{i=1}^n x_i w_i ;\\quad y = f(u)= \\left\\lbrace \n",
    "\t\t\t\t\\begin{array}{rl}\n",
    "\t\t\t\t\t1, & \\mbox{если $u \\geq 0$}\\\\\n",
    "\t\t\t\t\t-1, & \\mbox{если u<0}\n",
    "\t\t\t\t\\end{array}  \\right. . \n",
    "\\end{equation}\n",
    "\n",
    "Схема \"обучение с учителем\": есть задачник, содержащий входные значения и желаемый выход $\\tilde y \\in \\{-1, 1\\}$.\n",
    "\n",
    "$x_0$ | $x_1$ |...| $x_m$| $\\tilde y$\n",
    "-------------|--|-------------|----------------\n",
    "1 | $x_1^1$ | ... | $x_m^1$ | $y^1$\n",
    "1 | $x_1^2$ | ...| $x_m^2$ | $y^2$\n",
    "... | ... | ...| ... | ...\n",
    "\n",
    "Цель -- настроить веса нейрона $w_{0i}, w_{1i}, \\dots w_{mi}$ так, чтобы примеры из задачника были решены верно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Правило Розенблатта\n",
    "На шаге $t$ будем подавать очередной пример задачника и корректировать веса согласно формуле:\n",
    "\\begin{equation}\n",
    "    w_{ji}(t+1)= w_{ji}(t) + \\alpha x_i \\tilde{y}_j,\n",
    "\\end{equation}\n",
    "\n",
    "где $w_{ji}$ -- величина корректируемой синаптической связи, $t$ -- время, $x_i$ -- сигнал поданный в нейрон,  $\\tilde{y}_j$ -- желаемый отклик нейрона, $\\alpha$ -- параметр скорости обучения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Алгоритм обучения\n",
    "\n",
    "1. Все веса сети приравниваются к нулю или генерируются датчком случайных чисел. Задается параметр скорости обучения $\\alpha$.\n",
    "2. На вход сети подается очередной пример $x$ из задачника и расчитываются выходы сети $y$.\n",
    "3. Если сеть вернула ошибочное значение ($y \\neq \\tilde{y}$), то производится коррекция весов:\n",
    "\\begin{equation*}\n",
    "    w_{ji}(t+1)= w_{ji}(t) + \\alpha x_i \\tilde{y}_j,\n",
    "\\end{equation*}\n",
    "Если ответ сети верен, то веса остаются прежними:\n",
    "\\begin{equation*}\n",
    "    w_{ji}(t+1)= w_{ji}(t)\n",
    "\\end{equation*}\n",
    "4. Алгоритм продолжается до тех пор, пока все примеры задачника не будут верно обработаны сетью (пока веса не перестанут меняться)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Очень важно.** Если существует решение задачи (набор весов), то перцептрон обучается за конечное число шагов.\n",
    "\n",
    "*Вопрос о том, при каких условиях решение сущетсвует, рассматривается чуть поздее.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Пример: Реализация логической функции <<ИЛИ>>\n",
    "<img src=\"img/oneLayer/and_net.png\" height=\"10%\">\n",
    "\n",
    "ИЛИ | $x_1$ | $x_2$\n",
    "----|-------|------\n",
    "1 | 1 | 1\n",
    "1 | 1 | 0\n",
    "1 | 0 | 1\n",
    "0  | 0 | 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Поскольку мы будем использовать симметричную функцию активации\n",
    "\\begin{equation}\n",
    "        y = f(u)= \\left\\lbrace \n",
    "            \\begin{array}{rl}\n",
    "                1, & \\mbox{если }u > 0\\\\\n",
    "                -1, & \\mbox{если }u \\leq 0\n",
    "            \\end{array}  \\right. .\n",
    "\\end{equation}\n",
    "То перекодируем таблицу истинности. Кроме того добавим вход для веса $w_0$\n",
    "\n",
    "ИЛИ | $x_0$| $x_1$ | $x_2$\n",
    "----|-------|------\n",
    "1 | 1 | 1 | 1\n",
    "1 | 1 |1 | 0\n",
    "1 | 1 |0 | 1\n",
    "-1 | 1 | 0 | 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Инициализация\n",
    "Генерируем веса датчиком случайных чисел: \t\n",
    "\\begin{equation*}\n",
    "    w_0=0.1; \\quad w_1 = 0; \\quad w_2 = 0.3\n",
    "\\end{equation*}\n",
    "\n",
    "Выберем параметр скорости обучения: $\\alpha = 0.2$\n",
    "\n",
    "<img src=\"img/oneLayer/and_net0.png\" height=\"10%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1-я итерация\n",
    "Подаем первый пример:\n",
    "<img src=\"img/oneLayer/and_net1.png\" height=\"10%\">\n",
    "\n",
    "Расчитываем выход сети при заданных входах:\n",
    "\\begin{equation*}\n",
    "    u = 0 + 1\\cdot 0.1 +1\\cdot 0 +1\\cdot 0.3 = 0.4 \\qquad y = f(u) = 1\n",
    "\\end{equation*}\n",
    "\n",
    "Расчетный выход сети совпадает с желаемым => веса менять не нужно, переходим ко второй итерации.\n",
    "\n",
    "Подаем второй пример: $x_1=1$, $x_1 = 0$, $\\tilde{y} = 1$.\n",
    "\n",
    "Подаем третий пример: $x_1=0$, $x_1 = 1$, $\\tilde{y} = 1$.\n",
    "\n",
    "В обоих случаях ответы сети совпадают с желаемыми выходами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4-я итерация\n",
    "Подаем 4-й пример: $x_1=0$, $x_1 = 0$, $\\tilde{y} = 0$.\n",
    "\n",
    "Расчитываем ответ сети: $y=1$.\n",
    "\n",
    "Это неправильный ответ ($\\tilde y = -1$), нужно корректировать веса:\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\begin{split}\n",
    "    w_0(4)=w_0(3)+ \\alpha x_0\\cdot \\tilde y = 0.1 + 0.2\\cdot 1 \\cdot (-1) = -0.1 \\\\\n",
    "    w_1(4)=w_1(3)+ \\alpha x_1\\cdot \\tilde y = 0 +   0.2\\cdot 0 \\cdot (-1) = 0 \\\\\n",
    "    w_2(4)=w_2(3)+ \\alpha x_2\\cdot \\tilde y = 0.3 + 0.2\\cdot 0 \\cdot (-1) = 0.3\n",
    "    \\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "После этого опять подаем первый пример и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Вопрос.\n",
    "Можно ли при обучении по правилу Розенблатта использовать следующую функцию активации:\n",
    "\\begin{equation*}\n",
    "    y = f(u)= \\left\\lbrace \n",
    "        \\begin{array}{rl}\n",
    "            1, & \\mbox{если }u > 0\\\\\n",
    "            0, & \\mbox{если }u \\leq 0\n",
    "        \\end{array}  \\right. \n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Правило обучения Видроу-Хоффа\n",
    "\n",
    "Используется для нейронов с линейной функцией активации:\n",
    "\n",
    "\\begin{equation}\n",
    "    f(u) = k\\cdot u\n",
    "\\end{equation}\n",
    "\n",
    "*Для упрощения дальнейших выкладок примем $k=1$, на ход рассуждений это не влияет.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Обучение: идея\n",
    "\n",
    "* Обучение с учителем.\n",
    "* Возьмем $L$ примеров из задачника. Рассчитаем для них выходы. Далее можно рассчитать общую ошибку:\n",
    "\\begin{equation}\n",
    "    E = \\sum_{i=1}^{L} E(i) = \\frac{1}{2}\\sum_{i=1}^{L} \\left( y(i) - \\tilde y (i)\\right)^2\n",
    "\\end{equation}\n",
    "где $y(i)$ -- выходное значение нейрона для примера $i$, $\\tilde y (i)$ -- желаемое значение (эталон) для этого примера.\n",
    "* При обучении будем менять веса нейрона так, чтобы ошибка уменьшалась.\n",
    "\n",
    "PS Почему нельзя считать ошибку по формуле:\n",
    "\\begin{equation}\n",
    "    E = \\sum_{i=1}^{L} E(i) = \\frac{1}{2}\\sum_{i=1}^{L} \\left( y(i) - \\tilde y (i)\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Упрощение\n",
    "Для облегчения задачи положим $L=1$, тогда ошибку будем рассчитывать для каждого примера в отдельности:\n",
    "\\begin{equation*}\n",
    "    E = \\frac{1}{2} \\left( y - \\tilde y \\right)^2\n",
    "\\end{equation*}\n",
    "Распишем $y$ через входные значения $X=(x_1,\\dots, x_n)$ нейрона и его весовые коэффициенты:\n",
    "\\begin{equation*}\n",
    "    E = \\frac{1}{2} \\left( \\sum_{i=0}^n w_i x_i - \\tilde y \\right)^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Формулировка задачи\n",
    "Зафиксируем пример, на основе которого производится обучение, т.е. входные значения $X=(x_1,\\dots, x_n)$ и желаемое выходное значение $\\tilde y (i)$. Тогда ошибка сети для данного примера рассчитывается по формуле:\n",
    "\n",
    "\\begin{equation}\n",
    "    E = \\frac{1}{2} \\left( \\sum_{i=0}^n w_i x_i - \\tilde y \\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "**Требуется** так изменить веса нейрона $w_0,\\dots, w_n$, чтобы величина ошибки для данного примера уменьшилась.\n",
    "\n",
    "*Сформулированная задача -- типичная задача на поиск экстремума.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"img/oneLayer/3dSurf.png\" height=\"10%\">\n",
    "\n",
    "В качестве осей координат у нас веса сети $w_{0}, w_{1}, \\dots w_{n}$, поверхность -- величина ошибки при конкретных значениях весов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Метод градиентного спуска\n",
    "\n",
    "Задана функция нескольких переменных:\t$f = f(x_1,x_2,\\dots , x_n)$, требуется найти ее минимум.\n",
    "\n",
    "Будем осуществлять поиск в направлении наискорейшего спуска, которое задается вектором: $-\\nabla f$.\n",
    "\n",
    "Т.е. к точке минимума $x^* = (x_1^*, x_2^*,\\dots, x_n^*)$ будем приближаться итерационно, начиная с произвольной точки $x^0 = (x_1^0, x_2^0,\\dots, x_n^0)$. Каждое следующее приближение будем находить по формуле:\n",
    "\\begin{equation}\\label{eq:grad_metod}\n",
    "    x^{k+1} = x^{k} - \\alpha \\nabla f(x^k),\n",
    "\\end{equation}\n",
    "где $\\alpha$ --- параметр, регулирующий величину шага.\n",
    "\n",
    "Формула покоординатно расписывается следующим образом:\\pause\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        x^{k+1}_1 = x^{k}_1 - \\alpha \\frac{\\partial f}{\\partial x_1}\\Big|_{(x=x^k)},\\\\\n",
    "        \\dots \\\\\n",
    "        x^{k+1}_n = x^{k}_n - \\alpha \\frac{\\partial f}{\\partial x_n}\\Big|_{(x=x^k)}\n",
    "    \\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Решение\n",
    "Воспользуемся методом градиентного спуска. Тогда весовые коэффициенты нейрона должны измениться согласно следующей формуле:\n",
    "\\begin{equation}\n",
    "    \\begin{split}\n",
    "        w_{0}(t+1) = w_0(t) - \\alpha \\frac{\\partial E}{\\partial w_0(t)},\\\\\n",
    "        \\dots,\\\\\n",
    "        w_{j}(t+1) = w_j(t) - \\alpha \\frac{\\partial E}{\\partial w_j(t)},  \\\\\n",
    "        \\dots,\\\\\n",
    "        w_{n}(t+1) = w_n(t) - \\alpha \\frac{\\partial E}{\\partial w_n(t)}\n",
    "    \\end{split}\t\t\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Производная величины $E$\n",
    "Вычислим производные $\\frac{\\partial E}{\\partial w_j(t)}$: \n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial E}{\\partial w_j} = \\frac{\\partial \\left[\\frac{1}{2} \\left( \\left(\\sum_{i=0}^n w_i x_i \\right) - \\tilde y \\right)^2\\right]}{\\partial w_j}\n",
    "\\end{equation*}\n",
    "здесь $x_i=const$, $\\tilde y = const$\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\frac{\\partial E}{\\partial w_j} = \n",
    "        \\left( \\left(\\sum_{i=0}^n w_i x_i \\right) - \\tilde y \\right) \\frac{\\partial \\left( \\left(\\sum_{i=0}^n w_i x_i \\right) - \\tilde y \\right)}{\\partial w_j}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial E}{\\partial w_j} = ( y - \\tilde y ) x_j\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Дельта-правило\n",
    "Таким образом получили, что правило обучения Видроу-Хоффа (дельта-правило) должно быть записано следующим образом:\n",
    "\n",
    "*Пусть $w=(w_0,w_1,\\dots, w_n)$ -- вектор весовых коэффициентов нейрона, $x=(x_1,\\dots, x_n)$ -- входные значения нейрона, а $\\tilde y$ - желаемое выходное значение, соответствующее заданным входам. Тогда весовые коэффициенты сети следует изменять согласно следующей формуле:*\n",
    "\n",
    "\\begin{equation}\\label{eq:delta}\n",
    "    w_j(t+1) = w_j(t) - \\alpha ( y - \\tilde y ) x_j,\n",
    "\\end{equation}\n",
    "где $t$ - номер итерации, $\\alpha\\in(0,1)$ --- некоторый параметр (скорость обучения).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Алгоритм обучения Видроу-Хоффа\n",
    "\n",
    "1. Составляется задачник и задаются параметры: \n",
    "    * скорость обучения $\\alpha\\in(0,1)$ \n",
    "    * устраивающая точность, т.е. ошибка $E_{good}$, которую нужно достичь в процессе обучения\n",
    "    \n",
    "2. Случайным образом инициализируются весовые коэффициенты и порог сети.\n",
    "3. На входы сети подаются входные образы $x=(x_1,\\dots, x_n)$ и вычисляются выходные значения сети $y$.\n",
    "4. Осуществляется коррекция весовых коэффициентов согласно дельта-правилу.\n",
    "5. Алгоритм продолжается до тех пор, пока суммарная среднеквадратичная ошибка сети не станет меньше заданной: $E < E_{good}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сравнение правил Розенблатта и Видроу-Хоффа\n",
    "\n",
    "* Правило обучения Розенблатта \t\t\t\n",
    "\\begin{equation*}\n",
    "    w_j(t+1) = w_j(t) + \\alpha \\tilde y x_j,\n",
    "\\end{equation*}\n",
    "Обучение производится при $y \\neq \\tilde y$, при этом: $y \\in \\{-1,1\\}$ $\\tilde y \\in \\{-1,1\\}$.\n",
    "\n",
    "* Правило обучения Видроу-Хоффа\n",
    "\\begin{equation*}\n",
    "    w_j(t+1) = w_j(t) - \\alpha ( y - \\tilde y ) x_j,\n",
    "\\end{equation*}\n",
    "\n",
    "**Оба правила обучения можно записать в общей форме:**\n",
    "\\begin{equation*}\n",
    "        w_j(t+1) = w_j(t) - \\alpha ( y - \\tilde y ) x_j,\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Общее правило обучения\n",
    "1. Составляется задачник и задаются параметры: \n",
    "    * скорость обучения $\\alpha\\in(0,1)$;\n",
    "    * формулируется критерий, согласно которому останавливается обучение.\n",
    "    \n",
    "2. Случайным образом инициализируются весовые коэффициенты и порог сети.\n",
    "3. На входы сети подаются *случайно выбираемые* входные образы $x=(x_1,\\dots, x_n)$ из задачинка и вычисляются выходные значения сети $y$.\n",
    "4. Осуществляется коррекция весовых коэффициентов согласно дельта-правилу:\n",
    "    \\begin{equation*}\n",
    "        w_j(t+1) = w_j(t) - \\alpha ( y - \\tilde y ) x_j,\n",
    "\\end{equation*}\n",
    "5. Алгоритм продолжается до тех пор, пока не достигнут критерий останова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Выбор параметра скорости\n",
    "Слишком маленькая скорость | Слишком большая скорость\n",
    "-------------------------------|------------------\n",
    "<img src=\"img/oneLayer/alpha1.png\" height=\"10%\">|<img src=\"img/oneLayer/alpha2.png\" height=\"10%\">\n",
    "\n",
    "Параметр скорости обучения $\\alpha$ должен быть достаточно большим, иначе процесс коррекции весов будет <<топтаться на месте>> и  должен быть достаточно маленьким, иначе процесс коррекции весов может оказаться неустойчивым."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Как же тогда выбирать $\\alpha$?\n",
    "\n",
    "* Можно экспериментально (не получается с одним параметром, пробуем другой)\n",
    "* Можно выбирать $\\alpha$, которое будет уменьшаться в процессе обучения, например:\n",
    "\\begin{equation*}\n",
    "    \\alpha (t) = \\frac{1}{t},\n",
    "\\end{equation*}\n",
    "где $t$ -- номер итерации. (Тут возможны проблемы...)\n",
    "* Можно использовать адаптивный шаг обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Адаптивный шаг обучения\n",
    "*Адаптивный шаг обучения* -- такой параметр $\\alpha(t)$, который целенаправленно выбирается на каждом шаге алгоритма таким образом, чтобы минимизировать среднеквадратичную ошибку сети.\n",
    "\n",
    "Существует\n",
    "\n",
    "**Теорема.** Для линейной нейронной сети значение адаптивного шага обучения вычисляется на основе выражения:\n",
    "\\begin{equation}\n",
    "     \\alpha(t) = \\frac{1}{1 + \\sum_{i=1}^n x_i^2(t)} \n",
    " \\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Задача\n",
    "\n",
    "[Рубки леса](https://kolesov.nextgis.com/resource/1711/display). Есть выдела с ценными породами леса, на некоторых лес валят, а где-то нет. Возможно, это зависит от транспортной доступности? => \n",
    "\n",
    "*Задача:* построить классификатор, определяющий \"будут рубить\" или \"не будут рубить\" в зависимости от сложности дорожных условий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>descr</th>\n",
       "      <th>value</th>\n",
       "      <th>bg</th>\n",
       "      <th>asphalt</th>\n",
       "      <th>grunt</th>\n",
       "      <th>bad</th>\n",
       "      <th>GEOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>фон</td>\n",
       "      <td>-1</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>12250.0</td>\n",
       "      <td>24250.0</td>\n",
       "      <td>14750.0</td>\n",
       "      <td>POINT (15002780.01590729 5710921.961077135)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>склад</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>POINT (15026774.50471171 5779438.080579749)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>рубка</td>\n",
       "      <td>1</td>\n",
       "      <td>250.0</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>POINT (15026188.48691452 5779184.436417193)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>склад</td>\n",
       "      <td>1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>POINT (15025809.5597372 5778690.272296071)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>склад</td>\n",
       "      <td>1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>POINT (15025788.32522192 5778659.538064778)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat  descr  value      bg  asphalt    grunt      bad  \\\n",
       "0    1    фон     -1  2750.0  12250.0  24250.0  14750.0   \n",
       "1    2  склад      1     0.0  13750.0      0.0   2500.0   \n",
       "2    3  рубка      1   250.0  13750.0      0.0   2250.0   \n",
       "3    4  склад      1   500.0  13750.0      0.0   2250.0   \n",
       "4    5  склад      1   500.0  13750.0      0.0   2250.0   \n",
       "\n",
       "                                          GEOM  \n",
       "0  POINT (15002780.01590729 5710921.961077135)  \n",
       "1  POINT (15026774.50471171 5779438.080579749)  \n",
       "2  POINT (15026188.48691452 5779184.436417193)  \n",
       "3   POINT (15025809.5597372 5778690.272296071)  \n",
       "4  POINT (15025788.32522192 5778659.538064778)  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://kolesov.nextgis.com/api/resource/1707/csv\"\n",
    "\n",
    "loggs = pd.read_csv(url)\n",
    "loggs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bg</th>\n",
       "      <th>asphalt</th>\n",
       "      <th>grunt</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2750.0</td>\n",
       "      <td>12250.0</td>\n",
       "      <td>24250.0</td>\n",
       "      <td>14750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250.0</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500.0</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500.0</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2250.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bg  asphalt    grunt      bad\n",
       "0  2750.0  12250.0  24250.0  14750.0\n",
       "1     0.0  13750.0      0.0   2500.0\n",
       "2   250.0  13750.0      0.0   2250.0\n",
       "3   500.0  13750.0      0.0   2250.0\n",
       "4   500.0  13750.0      0.0   2250.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = loggs[['bg', 'asphalt', 'grunt', 'bad']].copy()\n",
    "Y = loggs['value'].copy()\n",
    "\n",
    "X.head()\n",
    "# Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239, 4)\n",
      "(239,)\n",
      "Произведение вектора весов и параметров примера 2: [ -750. 27500.     0. -2250.]\n",
      "Сумма произведения X*w:  6828500.0\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(Y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Зададим произвольный вектор из 4х элементов:\n",
    "w = np.array([-3, 2, 2, -1])\n",
    "\n",
    "print('Произведение вектора весов и параметров примера 2:', X[2, :]*w)\n",
    "print('Сумма произведения X*w: ', np.sum(X[2:, ] * w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Нейрон как классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Задача классификации:* формализованная задача, в которой имеется множество объектов (ситуаций), разделенных некоторым образом на классы. Задано конечное множество объектов, для которых известно, к каким классам они относятся. Это множество называется выборкой. Классовая принадлежность остальных объектов не известна. Требуется построить алгоритм, способный классифицировать произвольный объект из исходного множества.\n",
    "\n",
    "*Классифицировать объект:* значит, указать номер (или наименование) класса, к которому относится данный объект."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Пусть в $n$-мерном пространстве задано два класса $C_1$ и $C_2$.\n",
    "\n",
    "<img src=\"img/oneLayer/class.png\" height=\"10%\">\n",
    "\n",
    "\n",
    "Рассмотрим нейрон с пороговой функцией активации:\n",
    "\\begin{equation}\n",
    "    y = f(u) = \\left\\lbrace \n",
    "    \\begin{array}{rl}\n",
    "    1, & \\mbox{если $u \\geq 0$}\\\\\n",
    "    -1, & \\mbox{если u<0}\n",
    "    \\end{array}  \\right. .\n",
    "\\end{equation}\n",
    "\n",
    "Можно ли обучить нейрон так, чтобы \n",
    "* $y=1$ для любого $x \\in C_1$.\n",
    "* $y=-1$ для любого $x \\in C_2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Оказывается, настроить веса нейрона так, чтобы он позволял разделить два произвольных класса невозможно.\n",
    "\n",
    "Чтобы однослойный перцептрон функционировал корректно, два класса $C_1$ и $C_2$ должны быть линейно разделимыми.\n",
    "\n",
    "Линейно-разделимые классы| Линейно-неразделимые классы\n",
    "-------------------------------|------------------\n",
    "<img src=\"img/oneLayer/lin_razd.png\" height=\"10%\">|<img src=\"img/oneLayer/lin_ne_razd.png\" height=\"10%\">\n",
    "\n",
    "\n",
    "Если классы линейно-разделимы, то существует *разделяющая линия*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Почему перцептрон может работать только с линейно-разделимыми классами?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Нейрон выдает ответ ($+1$ или $-1$) в зависимости от того, какое значение потенциала $u=\\sum_{i=0}^n w_i x_i$ было получено при заданных входах $x=x_1,\\dots x_n$:\n",
    "\n",
    "\\begin{equation*}\n",
    "    y = f(u) = \\left\\lbrace \n",
    "    \\begin{array}{rl}\n",
    "    1, & \\mbox{если }u > 0\\\\\n",
    "    -1, & \\mbox{если }u<0\n",
    "    \\end{array}  \\right. .\n",
    "\\end{equation*}\n",
    "\n",
    "Таким образом при $u = 0$ происходит резкий переход значения $y$ от +1 к -1.\n",
    "\n",
    "\n",
    "*Какая фигура в пространстве задается уравнением $u=0$?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Уравнение $u=\\sum_{i=0}^n w_i x_i=0$ задает:\n",
    "\n",
    "* $n=2$: линию на плоскости: $w_0 + w_1x_1 + w_2x_2=0$\n",
    "* $n=3$: плоскость в пространстве: $w_0 + w_1x_1 + w_2x_2 + w_3 x_3=0$\n",
    "* $n>3$: гиперплоскость в многомерном пространстве: $w_0 + w_1x_1 + w_2x_2 + w_3 x_3 +\\dots +w_n x_n=0$\n",
    "\n",
    "Линия (плоскость, гиперплоскость) делит плоскость (пространство) на две полуплоскости (два полупространства): положительную и отрицательную."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
