{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Рекуррентные сети и моделирование последовательностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Последовательные данные\n",
    "\n",
    "* Финансовые временные ряды.\n",
    "* Аудиосигналы;\n",
    "* Тексты;\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Идея рекуррентной сети\n",
    "\n",
    "* Каждый новый элемент последовательности добавляет фрагмент информации к уже известной и обработанной моделью части данных.\n",
    "* Модель имеет состояние, которое не перезаписывается заново, а обновляется при обработке нового члена последовательности.\n",
    "\n",
    "Наример, чтение текста человеком: каждое новое слово не заставляет его забывать прочитанное ранее, а обновляет и дополняет \"историю\" и \"содержимое памяти\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Архитектура \n",
    "\n",
    "В нейронную сеть вводятся обратные связи.\n",
    "\n",
    "<img src=\"img/rnn/rnn_intro.png\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Динамическая система\n",
    "\n",
    "Пусть есть некоторая система, которая с течением времени меняет свое состояние:\n",
    "\n",
    "$$s^{(t)} = f(s^{(t-1)}; \\theta)$$\n",
    "\n",
    "(Рекуррентное выражение)\n",
    "\n",
    "Для конечного числа шагов $\\tau$ это выражение можно развернуть (избавиться от рекурсии):\n",
    "\n",
    "$$s^{(3)} = f(s^{(2)}; \\theta) = f(f(s^{(1)}; \\theta) ; \\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Динамическая система $s^{(t)} = f(s^{(t-1)}; \\theta)$ в виде развернутого графа вычислений. Каждая вершина -- состояние в момент $t$, функция $f$ отображает состояние в момент $t$ на состояние в момент $t+1$.](img/rnn/rnn_seq.png)\n",
    "Динамическая система $s^{(t)} = f(s^{(t-1)}; \\theta)$ в виде развернутого графа вычислений. \n",
    "\n",
    "* каждая вершина -- состояние в момент $t$, \n",
    "* функция $f$ отображает состояние в момент $t$ на состояние в момент $t+1$,\n",
    "* одни и те же параметры ($f$ и $\\theta$) используются на всех временных шагах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Нейронные сети с обратными связями - динамические системы\n",
    "\n",
    "![Сеть с обратными связями (без внешних входных сигналов)](img/rnn/rnn_syst.png).\n",
    "\n",
    "Сеть с обратными связями (без внешних входных сигналов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Системы, управляемые внешним сигналом\n",
    "\n",
    "Путь $x(t)$ - внешний сигнал. Состояния системы, управляемой сигналом описываются рекуррентным выражением:\n",
    "\n",
    "$$s^{(t)} = f(s^{(t-1)}, x^{(t)}; \\theta)$$.\n",
    "\n",
    "Состояние зависит от *всей* прошлой входной последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "В нейронных сетях состояния обычно представляются скрытыми блоками сети: \n",
    "$$h^{(t)} = f(h^{(t-1)}, x^{(t)}; \\theta)$$.\n",
    "\n",
    "\n",
    "<img src=\"img/rnn/rnn_intro.png\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Развертка рекуррентной сети\n",
    "\n",
    "Для вычислений и подбора весов сети \"разворачивают\" во времени, при этом зависимости выходов сети от входных сигналов и параметров становится легче проследить.\n",
    "\n",
    "![Пример развертки](img/rnn/rnn_unfold.png)\n",
    "Принципиальная схема и ее развертка во времени. (Гудфеллоу Я. и др. \"Глубокое обучение\").\n",
    "\n",
    "Рекуррентная сеть без выходов: обрабатывает входной сигнал $x$ и текущее состояние $h$, результат передается дальше во времени. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Преимущества развертки\n",
    "\n",
    "1. Независимо от длины входной последовательности размер входа в сеть фиксирован, а не список входов/состояний переменной длины. \n",
    "(Без развертки было бы: $h^{(t)} = g^{(t)} (x^{(t)}, x^{(t-1)}, x^{(t-2)}, \\dots, x^{(1)})$).\n",
    "2. Функция перехода $f$ одинакова на каждом шаге.\n",
    "\n",
    "Т.е. можно обучить *одну* модель $f$, работающую на всех временных шагах, а не обучать отдельно для каждого шага."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Распространенные схемы рекуррентных сетей\n",
    "\n",
    "1. Сети, порождающие выход на каждом временном шаге, и имеющие рекуррентные связи между скрытыми блоками.\n",
    "2. Сети, порождающие выход на каждом временном шаге, и имеющие рекуррентные связи между выходами на одном шаге и скрытыми блоками на следующем.\n",
    "3. Сети с рекуррентными связями между скрытыми блоками, которые читают последовательность целиком, а затем порождают единственный выход."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Сети с рекуррентными связями между скрытыми блоками\n",
    "Пример для задачи классификации: пусть $W$, $U$, $V$ -- матрицы весовых коэффициентов сети, тогда на каждом шаге:\n",
    "\n",
    "1. преобразуем входной сигнал и прошлое состояние в новое состояние сети:\n",
    "$$a^{(t)} = b + Wh^{(t-1)} + U x^{(t)}$$\n",
    "$$h^{(t)} = th(a^{(t)})$$\n",
    "\n",
    "2. вычисляем выход сети\n",
    "$$o^{(t)} = c + V h^{(t)}$$\n",
    "$$\\hat y^{(t)} = softmax(o^{(t)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Граф вычисления функции потерь сети и его развертка\n",
    "\n",
    "Для обучения требуется сначала развернуть всю последовательность, затем выполнить обратное распространение ошибки.\n",
    "\n",
    "![Граф вычислений функции потерь](img/rnn/rnn1.png)\n",
    "(Гудфеллоу Я. и др. \"Глубокое обучение\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Сети с рекурсией между выходами и скрытыми слоями\n",
    "\n",
    "![Граф вычислений функции потерь](img/rnn/rnn2.png)\n",
    "(Гудфеллоу Я. и др. \"Глубокое обучение\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Сеть менее мощная (способна обучиться меньшему числу функций):\n",
    " * выход сети $o$ на предыдущем шаге - единственная информация, которую можно передавать в будущее;\n",
    " * выход сети $o$ - целевая переменная, т.е. сеть обучается возвращать $o$, сложно включить полезные сведения о состоянии сети для передачи их в будущее (в $o$ отсутствует важная информация о прошлом).\n",
    " \n",
    "Не требует развертки во времени всей последовательности:\n",
    " * можно обучать каждый шаг по отдельности;\n",
    " * параллельность обработки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Сети с единственным выходом в конце последовательности\n",
    "\n",
    "\n",
    "![Граф вычислений функции потерь](img/rnn/rnn3.png)\n",
    "(Гудфеллоу Я. и др. \"Глубокое обучение\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Пример: создание рекуррентной сети в TensorFlow\n",
    "\n",
    " * Создадим рекуррентную сеть, способную обрабатывать последовательности.\n",
    " * Будем работать с низкоуровневыми инструментами TensorFlow.\n",
    "\n",
    "Сеть реализует в нейронах, отвечающих за состояние, следующую функцию:\n",
    "\n",
    "$$\n",
    "h^{(t)} = th(W_x x^{(t)} + W_h h^{(t-1)} + b)\n",
    "$$\n",
    "$W_x$, $W_h$ и $b$ - обучаемые веса и пороги, общие для всех временных шагов.\n",
    "\n",
    "В основе кода лежит [данная реализация.](https://github.com/Hezi-Resheff/Oreilly-Learning-TensorFlow/blob/master/05__text_and_visualizations/vanilla_rnn_with_tfboard.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Задача: классификация изображений MNIST\n",
    "\n",
    "Изображение можно рассматривать, как последовательность:\n",
    "\n",
    " * каждое изображение - последовательность строк (или столбцов);\n",
    " * 28х28 пиксельное изображение - это последовательность из 28-ми элементов, каждый элемент - вектор из 28-ми пикселей;\n",
    " * пространственную структуру изображения можно заменить на пространственно-временную.\n",
    " \n",
    "Создадим сеть, которая на вход принимает столбцы пикселей один за другим: 0, 1, ..., 27. После получения последнего столбца сеть должна выдать номер класса (цифру на изображении)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Имортируем необходимые библиотеки, считываем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline  \n",
    "\n",
    "import sys\n",
    "\n",
    "DATA_DIR = '/tmp/data' if not 'win32' in sys.platform else \"c:\\\\tmp\\\\data\"\n",
    "STEPS = 1000\n",
    "MINIBATCH_SIZE = 50\n",
    "mnist = input_data.read_data_sets(DATA_DIR, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Одно из изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_IX_IN_DATASET = 0\n",
    "\n",
    "first_img = mnist.train.images[IMAGE_IX_IN_DATASET].reshape(28, 28)\n",
    "first_lbl = mnist.train.labels[IMAGE_IX_IN_DATASET].argmax()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(first_img, cmap='gray')\n",
    "plt.gca().get_xaxis().set_visible(False)\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "plt.title(\"Вообще-то это должно быть {}\".format(first_lbl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Определим параметры, с которыми будет работать сеть:\n",
    " * размер элемента (число пикселей в колонке);\n",
    " * длина последовательности;\n",
    " * число классов;\n",
    " * размер минипакета для обучения;\n",
    " * число нейронов, отвечающих за вектор состояния. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "element_size = 28\n",
    "time_steps = 28\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Параметры для хранения входов и выходов сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "_inputs = tf.placeholder(tf.float32,\n",
    "                         shape=[None, time_steps, element_size],\n",
    "                         name='inputs')\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Веса входного слоя и слоя состояний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('rnn_weights'):\n",
    "    with tf.name_scope(\"W_x\"):\n",
    "        Wx = tf.Variable(tf.zeros([element_size, hidden_layer_size]))\n",
    "    with tf.name_scope(\"W_h\"):\n",
    "        Wh = tf.Variable(tf.zeros([hidden_layer_size, hidden_layer_size]))\n",
    "    with tf.name_scope(\"Bias\"):\n",
    "        b_rnn = tf.Variable(tf.zeros([hidden_layer_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Вычисление нового состояния по входному сигналу и вектору старых состояний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def rnn_step(previous_hidden_state, x):\n",
    "    current_hidden_state = tf.tanh(\n",
    "            tf.matmul(previous_hidden_state, Wh) +\n",
    "            tf.matmul(x, Wx) + b_rnn)\n",
    "    \n",
    "    return current_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Развертка слоя состояний во времени:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Осуществим развертку функцией scan\n",
    "# Текущие размерности данных: (batch_size, time_steps, element_size)\n",
    "processed_input = tf.transpose(_inputs, perm=[1, 0, 2])\n",
    "# Новые размерности данных: (time_steps, batch_size, element_size)\n",
    "\n",
    "\n",
    "initial_hidden = tf.zeros([batch_size, hidden_layer_size])\n",
    "# Развертка во времени\n",
    "all_hidden_states = tf.scan(rnn_step,\n",
    "                            processed_input,\n",
    "                            initializer=initial_hidden, name='states')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Пример работы функции scan\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def sum_(a, x):\n",
    "    return a + x\n",
    "\n",
    "elems = np.array([\"T\", \"e\", \"n\", \"s\", \"o\", \"r\",  \" \",  \"F\", \"l\", \"o\", \"w\"])\n",
    "scan_sum = tf.scan(sum_, elems)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(scan_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Определим веса и пороги выходного слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('linear_layer_weights') as scope:\n",
    "    with tf.name_scope(\"W_linear\"):\n",
    "        Wl = tf.Variable(tf.truncated_normal([hidden_layer_size, num_classes],\n",
    "                                             mean=0, stddev=.01))\n",
    "    with tf.name_scope(\"Bias_linear\"):\n",
    "        bl = tf.Variable(tf.truncated_normal([num_classes],\n",
    "                                             mean=0, stddev=.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Определим функцию выхода сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_linear_layer(hidden_state):\n",
    "    return tf.matmul(hidden_state, Wl) + bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('linear_layer_weights') as scope:\n",
    "    # Рассчитаем выходы сети для каждого момента времени\n",
    "    all_outputs = tf.map_fn(get_linear_layer, all_hidden_states)\n",
    "    # Нас интересует в основном последний ответ-- h_28\n",
    "    output = all_outputs[-1]\n",
    "\n",
    "# Функция потерь\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y))\n",
    "\n",
    "# Отпимизация\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(1.5e-3).minimize(cross_entropy)\n",
    "    # train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "\n",
    "# Точность в процентах\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(output, 1))\n",
    "    accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Тестовые данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_data = mnist.test.images[:batch_size].reshape((-1, time_steps, element_size))\n",
    "test_label = mnist.test.labels[:batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Вычислительный граф определен. Запустим расчеты на этом графе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(5000):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Переформатируем данные, чтобы получтить 28 элементов по 28 пикселей\n",
    "            batch_x = batch_x.reshape((batch_size, time_steps, element_size))\n",
    "            sess.run([train_step], feed_dict={_inputs: batch_x, y: batch_y})\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                acc, loss, = sess.run([accuracy, cross_entropy],\n",
    "                                      feed_dict={_inputs: batch_x,\n",
    "                                                 y: batch_y})\n",
    "                print(\"Iter \" + str(i) + \", Потеря на пакете= \" +\n",
    "                      \"{:.6f}\".format(loss) + \", Точность (обуч.)= \" +\n",
    "                      \"{:.5f}\".format(acc))\n",
    "            if i % 100 == 0:\n",
    "                # Вычисляем точность для 128 примеров\n",
    "                acc = sess.run([accuracy],\n",
    "                                        feed_dict={_inputs: test_data,\n",
    "                                                   y: test_label})\n",
    "\n",
    "    test_acc = sess.run(accuracy, feed_dict={_inputs: test_data,\n",
    "                                             y: test_label})\n",
    "print(\"Точность (тест):\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
